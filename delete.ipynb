{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fa7e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20260, 512]), torch.Size([20260, 40]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = torch.load('variables/latents_celeba_vgg16.pt', weights_only=True)\n",
    "labels = torch.load('variables/labels.pt', weights_only=True)\n",
    "activations.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edfe39fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weights', 'biases']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.linear_cav import LinearCAV\n",
    "\n",
    "model1 = LinearCAV(40, 512, device='cpu')\n",
    "list(model1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a1f5c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.6655,  0.1851,  0.7804,  ..., -1.1509,  1.9469, -0.3770],\n",
       "         [ 0.9161,  2.3566, -1.1967,  ...,  1.1529,  0.2808,  1.1489],\n",
       "         [-1.0718,  0.0517, -1.3662,  ..., -0.2648, -1.6436, -0.0631],\n",
       "         ...,\n",
       "         [-0.3991, -1.0432,  0.2954,  ...,  0.8221,  1.7303, -0.3322],\n",
       "         [-1.3112, -0.1184,  0.0181,  ...,  1.0871, -0.7002, -0.4613],\n",
       "         [ 0.5916, -0.9506,  0.5127,  ..., -0.4886, -1.5401, -0.9758]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0766e+00, -2.0249e-01, -1.2705e+00, -1.2950e-01,  2.3764e-02,\n",
       "          -2.2701e-01, -1.2777e+00,  5.9295e-01,  2.3917e-01, -4.0568e-01,\n",
       "           3.0885e-01,  6.7448e-01, -1.0682e+00, -9.9402e-01,  3.6662e-01,\n",
       "           5.4662e-02,  2.4230e+00, -2.0279e-01,  1.0643e+00, -1.2756e-02,\n",
       "          -6.2723e-01, -2.1509e+00, -1.4944e+00,  3.7717e-01, -5.0100e-01,\n",
       "          -1.5439e+00, -2.1828e+00,  3.0414e-01,  2.9599e-01,  1.3980e+00,\n",
       "           8.7687e-01, -1.6100e+00, -1.3180e+00,  4.8359e-01,  2.8683e-01,\n",
       "           5.4259e-01, -7.0041e-01, -3.2132e-01, -6.8122e-01, -8.8772e-01,\n",
       "          -1.2144e-01,  7.9257e-01, -1.5815e-01,  1.3887e+00,  8.3151e-01,\n",
       "           2.0987e-02, -2.1557e-01, -9.5149e-01, -7.4984e-01,  1.0703e-01,\n",
       "          -6.0902e-01, -7.1660e-01,  5.7320e-02, -1.1291e-01,  4.9434e-01,\n",
       "          -1.8516e+00, -1.6482e+00, -1.6703e+00, -7.6967e-01,  5.1537e-01,\n",
       "          -3.4785e-01,  3.7392e-01, -1.3335e+00,  4.3247e-01, -9.1724e-02,\n",
       "          -1.8753e-01, -5.5918e-01, -3.9351e-01,  1.0772e+00, -4.0665e-01,\n",
       "           1.6689e-01, -1.7726e-01, -1.3262e+00,  1.1920e+00,  6.6112e-02,\n",
       "          -9.8131e-01,  1.0666e-02, -1.3635e-01,  7.4778e-01,  1.2822e+00,\n",
       "           1.7412e+00,  1.4531e+00,  4.0696e-02, -6.9494e-01, -1.1805e+00,\n",
       "           1.0268e+00, -1.9293e-01, -1.8184e+00, -1.6078e+00,  1.0222e-01,\n",
       "           3.4385e-01,  1.4434e+00, -1.4813e-01,  1.9747e+00, -1.4065e+00,\n",
       "          -1.0290e+00, -7.2197e-01,  9.4797e-01,  7.3987e-02, -4.8313e-01,\n",
       "           1.2291e+00, -1.1651e+00,  5.2546e-01, -7.8095e-01, -1.1019e+00,\n",
       "           6.1373e-01, -1.6996e+00,  6.2820e-01, -4.7420e-01, -3.8754e-01,\n",
       "          -8.0247e-02, -1.8228e-01,  6.2680e-01,  1.4552e+00,  2.3392e-01,\n",
       "          -6.4509e-01,  1.9208e+00, -4.2662e-01,  5.5114e-01,  1.0748e-01,\n",
       "           5.7214e-01, -1.6476e+00, -4.9705e-01, -2.7550e-01, -5.7478e-01,\n",
       "           2.3159e-01, -1.8713e-01,  1.2436e-01, -2.3212e-01, -9.5536e-01,\n",
       "          -1.0722e+00, -2.5057e+00,  7.3657e-01, -1.1692e+00,  1.2681e+00,\n",
       "           1.1967e+00, -1.1886e-01,  1.4884e-03, -8.3681e-01, -1.0324e+00,\n",
       "          -1.2718e-01, -2.3741e-01,  1.5538e-01,  2.3133e-01,  2.0081e-01,\n",
       "           1.4767e+00, -5.0997e-01, -1.2747e-01,  3.4630e-01,  1.9121e+00,\n",
       "           1.2038e+00,  8.5268e-01,  9.5541e-01,  1.1302e+00, -4.4871e-01,\n",
       "           2.3743e+00, -8.6601e-01,  1.0195e+00, -2.7692e-02, -5.9643e-01,\n",
       "          -1.1158e+00, -1.7169e+00, -5.3370e-01,  1.4399e-01, -3.3058e-01,\n",
       "          -3.6805e-01,  1.9714e+00,  4.9583e-01,  1.9943e+00, -7.3657e-01,\n",
       "           5.1592e-01,  1.0277e-01,  8.7683e-01, -3.5600e-02, -3.9763e-01,\n",
       "          -1.7791e+00, -1.0869e+00,  1.3191e-02, -1.2345e+00, -1.1623e+00,\n",
       "           1.2537e+00,  6.0964e-01, -4.6987e-01,  6.9381e-01,  1.3159e+00,\n",
       "           5.8419e-01, -7.6188e-01, -7.1716e-01, -7.2485e-01, -1.1207e+00,\n",
       "          -3.7618e-01, -4.5126e-01,  5.1685e-01, -1.3765e-01, -1.1722e+00,\n",
       "           4.4152e-01,  3.9822e-01, -1.4507e+00, -8.4152e-01, -1.2309e+00,\n",
       "           2.8466e-01, -1.8335e-01,  1.2748e-01, -7.7631e-01, -3.4905e-01,\n",
       "           3.1098e-01,  1.1243e+00, -5.5504e-03, -4.3460e-01,  5.9032e-01,\n",
       "          -5.0401e-01,  8.6374e-01, -6.9904e-01, -5.6467e-01, -1.1139e+00,\n",
       "           1.2408e+00, -1.3176e+00,  5.4377e-01, -9.3191e-01,  5.6469e-01,\n",
       "          -6.4795e-01,  1.8932e+00, -5.1935e-01, -4.7393e-01,  6.5652e-01,\n",
       "           3.5772e-02, -1.2143e+00, -1.2681e+00,  7.8107e-01,  1.5915e+00,\n",
       "           1.5867e-01, -1.2971e-01, -7.3441e-01,  1.8792e+00,  1.1180e+00,\n",
       "           1.5268e+00, -4.1675e-01, -1.8205e-02,  1.5499e-01, -9.9789e-01,\n",
       "          -1.6330e-01, -9.1594e-01,  6.3503e-01,  4.7759e-01, -4.7218e-01,\n",
       "          -8.0130e-01,  8.3725e-01, -1.0687e-01, -1.3723e+00, -2.9372e-01,\n",
       "           8.9227e-01, -2.0331e-01, -1.0102e-01, -1.1617e+00,  1.4531e+00,\n",
       "          -1.0902e-01,  2.6745e-01, -3.5236e-01, -3.9049e-01,  1.4337e+00,\n",
       "          -1.3004e+00,  2.7362e-01,  2.7635e-01,  1.3799e+00, -7.0879e-03,\n",
       "          -4.4571e-01,  1.7585e+00, -5.0956e-01, -4.2329e-01, -2.0863e+00,\n",
       "           4.0302e-01,  1.1044e+00,  1.9108e+00, -2.1458e-01,  2.2704e-01,\n",
       "           5.2918e-01, -5.5596e-01,  2.7299e-01,  6.6269e-02, -1.1420e+00,\n",
       "           2.6087e-01,  1.8482e-01,  3.5717e-01,  8.0485e-01, -1.0791e+00,\n",
       "           1.4430e+00, -2.0241e+00, -6.9942e-01, -3.1770e-02, -9.1161e-02,\n",
       "          -1.2314e+00, -4.0424e-01,  2.8279e+00,  8.0999e-01, -9.4858e-01,\n",
       "          -5.7096e-01, -8.2460e-01, -1.2309e-01,  9.0566e-03,  1.0988e+00,\n",
       "          -1.3068e+00, -2.0387e+00,  1.5633e-01, -4.8228e-01,  3.4638e-01,\n",
       "           1.0511e-01, -8.5697e-01,  4.8782e-01,  8.6987e-01,  8.7758e-01,\n",
       "           9.0033e-02,  1.5315e+00,  1.8718e+00,  1.2747e+00,  2.4432e-01,\n",
       "           3.4071e-01,  3.0483e+00, -1.0290e+00, -4.1106e-01,  1.4560e+00,\n",
       "          -7.1901e-01,  4.6109e-01, -1.4918e+00,  7.7373e-01, -7.0307e-01,\n",
       "          -9.6172e-02, -1.2934e+00,  8.2127e-01, -1.5318e+00, -7.0563e-01,\n",
       "          -3.8089e-01, -1.0086e+00, -1.5860e+00, -6.5110e-02,  1.1061e+00,\n",
       "           4.5252e-01,  1.7668e+00, -5.0890e-01,  1.1518e+00,  5.0034e-01,\n",
       "           1.8131e-01,  1.7128e+00,  7.0930e-01,  1.9544e-03,  2.0877e-01,\n",
       "           6.1241e-03, -1.9359e-01, -8.5113e-01, -1.1310e+00, -9.3876e-01,\n",
       "           8.5398e-01, -8.3610e-01,  1.1550e+00, -6.7139e-01,  9.9668e-01,\n",
       "          -6.0762e-01,  1.4271e+00,  1.0624e+00,  1.8256e-01, -2.9737e-01,\n",
       "           1.9374e+00,  7.0869e-01, -4.1492e-01, -3.9939e-01, -1.1220e+00,\n",
       "          -5.3679e-01, -1.1205e+00,  2.0488e+00, -1.9246e+00, -1.0627e+00,\n",
       "          -1.0156e+00, -6.7871e-01, -8.6054e-01, -1.9767e-01,  7.7867e-01,\n",
       "          -8.5921e-01,  1.9697e+00, -1.0681e+00, -1.2102e+00,  1.4408e+00,\n",
       "           4.3625e-01, -1.1909e-01,  1.9318e-01, -4.8734e-01,  5.7697e-01,\n",
       "          -1.7083e+00, -7.3813e-01,  4.3992e-01,  1.0861e-01,  9.6334e-02,\n",
       "           4.5403e-01, -3.7870e-01,  6.1237e-01, -2.0111e+00,  1.4631e+00,\n",
       "           3.4527e-01,  1.7584e-02,  1.7179e+00,  2.3657e-01, -4.2994e-01,\n",
       "          -1.4341e+00, -1.4599e-01, -7.4544e-01, -6.1744e-01, -1.7149e+00,\n",
       "          -2.5973e+00,  4.6784e-01, -1.4313e+00,  2.1299e-01,  2.3317e+00,\n",
       "          -6.3937e-01, -1.1059e-01,  7.1897e-01, -2.4567e-01, -8.0395e-01,\n",
       "           1.1415e+00,  8.5488e-01, -5.4047e-01,  6.8737e-01,  1.8793e+00,\n",
       "          -2.5283e-01, -6.6849e-02,  2.1272e+00,  1.5425e+00, -1.1534e-01,\n",
       "          -1.3476e+00, -1.1489e+00, -1.2989e+00,  7.1935e-01, -3.5661e-01,\n",
       "           4.9988e-01,  8.0533e-01, -1.2852e+00,  1.4158e+00, -1.2793e+00,\n",
       "           5.6202e-01,  8.6569e-01, -9.6799e-02,  1.2082e-01,  1.1125e+00,\n",
       "          -2.5713e+00, -1.4263e+00,  4.0679e-01, -7.6861e-01,  1.5947e-01,\n",
       "          -9.7451e-01, -1.4480e+00, -1.7826e-02, -9.3778e-01,  3.9223e-01,\n",
       "          -1.6080e+00, -5.8733e-01, -1.1251e+00, -1.2556e+00,  4.3209e-01,\n",
       "           1.7546e+00, -1.6539e+00,  4.8428e-01, -8.4919e-01,  1.4806e+00,\n",
       "           9.7720e-01,  1.6485e+00, -2.9353e-01, -2.9021e-01,  8.2809e-01,\n",
       "           2.4543e-01, -7.3143e-02, -9.2921e-01, -9.8426e-02, -1.8365e+00,\n",
       "          -1.1040e+00, -2.4710e+00, -2.5169e-01, -7.1844e-01,  7.0988e-01,\n",
       "          -2.1721e+00, -1.7774e+00, -1.9209e+00, -4.2703e-01,  4.6751e-01,\n",
       "           1.1210e-01, -5.9688e-01,  6.5227e-01, -6.9530e-01, -1.1177e-01,\n",
       "          -2.1696e-01, -1.0603e+00, -1.0814e-01, -4.7569e-01,  1.4615e+00,\n",
       "           9.4479e-01, -3.3612e-01, -1.1738e+00, -1.5490e-01,  3.9651e-01,\n",
       "          -4.5077e-01, -1.0082e+00, -1.7807e+00, -1.0190e-01,  1.8662e-01,\n",
       "          -4.7780e-01, -2.7400e-01,  1.7179e+00, -4.9725e-02,  8.7225e-01,\n",
       "          -7.7643e-01, -2.4510e-01, -1.0009e+00,  9.6013e-01, -8.6439e-01,\n",
       "          -2.2839e-01,  1.2644e+00]], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7d5da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs1 = torch.load('results/cavs-linear:alpha0_lr0.1/cavs.pt', weights_only=True)\n",
    "model1.weights.data = cavs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e732fe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(cavs1, model1.weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8cf0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), 'checkpoints/lcav_vgg16_celeba.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a48f394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.cav import compute_all_cavs\n",
    "\n",
    "scavs = compute_all_cavs(activations, labels)\n",
    "scavs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a24c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(scavs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19daca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.signal_cav import SignalCAV\n",
    "\n",
    "model = SignalCAV(scavs, torch.randn(scavs.shape), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1539d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoints/scav_vgg16_celeba.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c4a36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = torch.load(\"checkpoints/scav_vgg16_celeba.pth\", weights_only=True)\n",
    "dict['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0d16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents1 = torch.load(\"variables/latents_diffae.pt\", weights_only=True)\n",
    "latents2 = torch.load(\"variables/latents.pt\", weights_only=True)\n",
    "latents3 = torch.load(\"variables/latents_celeba_vgg16.pt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab274b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([202599, 512])\n",
      "torch.Size([20260, 512])\n",
      "torch.Size([20260, 512])\n"
     ]
    }
   ],
   "source": [
    "print(latents1.shape)\n",
    "print(latents2.shape)\n",
    "print(latents3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4c4f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "          -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.],\n",
       "         [-1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "           1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1.],\n",
       "         [-1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,\n",
       "          -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
       "          -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
       "         [-1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
       "          -1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.],\n",
       "         [ 1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
       "          -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
       "          -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.]]),\n",
       " tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1.],\n",
       "         [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1 = torch.load(\"variables/labels_diffae.pt\", weights_only=True)\n",
    "labels2 = torch.load(\"variables/labels.pt\", weights_only=True)\n",
    "labels1[:5], labels2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36356b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
